{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [ ] Double check the data processing and make sure pre-Dx intervals are correct\n",
    "- [ ] Pre-Dx intervals (earliest time before Dx at which we can predict positive for each positive patient)\n",
    "- [ ] Relative risk plot\n",
    "\n",
    "## Notes\n",
    "\n",
    "- The trajectories here are much longer and span more heterogeneous time periods than CancerRiskNet\n",
    "- We need to think about how to adapt this to better suit our rare disease use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import tensorflow as tf\n",
    "import typing as t\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from joblib import delayed\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "\n",
    "from keras import layers, ops\n",
    "\n",
    "from lpm.data.datasets.risknet import Patient\n",
    "from lpm.data.datasets.risknet import (\n",
    "    BalancedRiskNetBatchGenerator,\n",
    "    PatientCollection,\n",
    "    RiskNetBatchGenerator,\n",
    "    RiskNetConfig,\n",
    "    TrajectoryValidator,\n",
    ")\n",
    "from lpm.data.datasets.risknet.dataset import deserialize_patient\n",
    "from lpm.data.datasets.risknet.sequence import encode_trajectories\n",
    "from lpm.model import RiskNet\n",
    "from lpm.model.risknet import (\n",
    "    get_eval_scores,\n",
    "    get_predictions_and_labels,\n",
    "    predict_patient,\n",
    ")\n",
    "from lpm.model.risknet.utils import compute_endpoint_metrics\n",
    "from lpm.utils.progress import ParallelTqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_diagnosis_code_info(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\"\"\"\n",
    "    return pd.read_csv(file_path, usecols=[\"CODE\", \"DESCRIPTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_patients_parallel(\n",
    "    file_list: t.List[str | Path],\n",
    "    trajectory_validator: TrajectoryValidator,\n",
    "    num_processes: int,\n",
    ") -> PatientCollection:\n",
    "    \"\"\"Deserialize patients from JSON.\"\"\"\n",
    "\n",
    "    parallel = ParallelTqdm(total_tasks=len(file_list), n_jobs=num_processes)\n",
    "\n",
    "    patients = parallel(\n",
    "        delayed(deserialize_patient)(f, trajectory_validator) for f in file_list\n",
    "    )\n",
    "\n",
    "    return PatientCollection(*patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    data_dir: Path, trajectory_validator: TrajectoryValidator, num_processes: int\n",
    ") -> t.Tuple[\n",
    "    PatientCollection, PatientCollection, PatientCollection, PatientCollection\n",
    "]:\n",
    "    \"\"\"Load a dataset from disk.\"\"\"\n",
    "    deserializer = functools.partial(\n",
    "        deserialize_patients_parallel,\n",
    "        trajectory_validator=trajectory_validator,\n",
    "        num_processes=num_processes,\n",
    "    )\n",
    "\n",
    "    train_pos = deserializer(list(data_dir.glob(\"train/pos/*.json\")))\n",
    "    train_neg = deserializer(list(data_dir.glob(\"train/neg/*.json\")))\n",
    "    test_pos = deserializer(list(data_dir.glob(\"test/pos/*.json\")))\n",
    "    test_neg = deserializer(list(data_dir.glob(\"test/neg/*.json\")))\n",
    "\n",
    "    return train_pos, train_neg, test_pos, test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_from_patients(patients: PatientCollection) -> np.ndarray:\n",
    "    \"\"\"Build a vocabulary from a list of patients.\"\"\"\n",
    "    all_codes = []\n",
    "    for pt in patients:\n",
    "        codes = [event[1] for event in pt.events]\n",
    "        all_codes.extend(codes)\n",
    "    return np.unique(all_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = Path(\"../../data/outputs/run/2024-10-16_06-24-13\")\n",
    "\n",
    "cfg = OmegaConf.load(run_dir / \".hydra/config.yaml\")\n",
    "model: RiskNet = keras.models.load_model(run_dir / \"risknet.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_validator = TrajectoryValidator(cfg.data)\n",
    "\n",
    "train_pos, train_neg, test_pos, test_neg = load_dataset(\n",
    "    Path(cfg.paths.raw), trajectory_validator, cfg.preprocess.num_processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = RiskNetBatchGenerator(\n",
    "    batch_size=25,\n",
    "    tokenizer=model.tokenizer,\n",
    "    max_codes=cfg.model.max_sequence_length,\n",
    "    n_trajectories=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores = get_eval_scores(\n",
    "    model,\n",
    "    batch_gen.flow(test_pos, test_neg, shuffle=False),\n",
    "    class_labels=cfg.data.month_endpoints,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(eval_scores[\"endpoint_metrics\"], orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = get_predictions_and_labels(\n",
    "    model, batch_gen.flow(test_pos, test_neg, shuffle=False)\n",
    ")\n",
    "y_true = pd.DataFrame(y_true, columns=[f\"y_true_{i}\" for i in range(y_true.shape[1])])\n",
    "y_pred = pd.DataFrame(y_pred, columns=[f\"y_pred_{i}\" for i in range(y_pred.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_to_idx = {ep: i for i, ep in enumerate(cfg.data.month_endpoints)}\n",
    "idx_to_endpoint = {i: ep for i, ep in enumerate(cfg.data.month_endpoints)}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curves\n",
    "\n",
    "roc_data = []\n",
    "for ep_idx in range(y_true.shape[1]):\n",
    "    ep_name = idx_to_endpoint[ep_idx]\n",
    "\n",
    "    y_true_var = f\"y_true_{ep_idx}\"\n",
    "    y_pred_var = f\"y_pred_{ep_idx}\"\n",
    "    fpr_ep, tpr_ep, _ = skm.roc_curve(y_true[y_true_var], y_pred[y_pred_var])\n",
    "\n",
    "    roc_data_ep = pd.DataFrame({\"fpr\": fpr_ep, \"tpr\": tpr_ep, \"endpoint\": ep_name})\n",
    "    roc_data.append(roc_data_ep)\n",
    "\n",
    "roc_data = pd.concat(roc_data)\n",
    "\n",
    "url = \"../../data/temp/roc_data.json\"\n",
    "roc_data.to_json(url, orient=\"records\")\n",
    "\n",
    "roc_chart = (\n",
    "    alt.Chart(url, width=300, height=300)\n",
    "    .mark_line(interpolate=\"step-after\")\n",
    "    .encode(\n",
    "        alt.X(\"fpr:Q\").axis(grid=False, tickCount=5).title(\"False Positive Rate (FPR)\"),\n",
    "        alt.Y(\"tpr:Q\").axis(grid=False, tickCount=5).title(\"True Positive Rate (TPR)\"),\n",
    "        alt.Color(\"endpoint:O\").legend().title(None),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = []\n",
    "for ep_idx in range(y_true.shape[1]):\n",
    "    ep_name = idx_to_endpoint[ep_idx]\n",
    "\n",
    "    y_true_var = f\"y_true_{ep_idx}\"\n",
    "    y_pred_var = f\"y_pred_{ep_idx}\"\n",
    "    p_ep, r_ep, _ = skm.precision_recall_curve(y_true[y_true_var], y_pred[y_pred_var])\n",
    "\n",
    "    pr_data_ep = pd.DataFrame({\"precision\": p_ep, \"recall\": r_ep, \"endpoint\": ep_name})\n",
    "    pr_data.append(pr_data_ep)\n",
    "\n",
    "pr_data = pd.concat(pr_data)\n",
    "\n",
    "url = \"../../data/temp/pr_data.json\"\n",
    "pr_data.to_json(url, orient=\"records\")\n",
    "\n",
    "pr_chart = (\n",
    "    alt.Chart(url, width=300, height=300)\n",
    "    .mark_line(interpolate=\"step-after\")\n",
    "    .encode(\n",
    "        alt.X(\"recall:Q\").axis(grid=False, tickCount=5).title(\"Recall\"),\n",
    "        alt.Y(\"precision:Q\").axis(grid=False, tickCount=5).title(\"Precision\"),\n",
    "        alt.Color(\"endpoint:O\").legend().title(None),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = (\n",
    "    alt.hconcat(roc_chart, pr_chart)\n",
    "    .resolve_scale(color=\"independent\")\n",
    "    .configure_view(strokeOpacity=0)\n",
    "    .configure_axis(titlePadding=10)\n",
    ")\n",
    "\n",
    "chart.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize ICD10 Code Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_embeddings = model.embedding.token_emb.get_weights()[0]\n",
    "code_embeddings = pd.DataFrame(code_embeddings, index=model.tokenizer.get_vocabulary())\n",
    "code_embeddings = code_embeddings.iloc[2:] # remove the padding and UNK tokens\n",
    "code_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = TSNE(n_components=2, random_state=42)\n",
    "code_embeddings_2d = reducer.fit_transform(code_embeddings)\n",
    "\n",
    "code_embeddings_2d = pd.DataFrame(\n",
    "    code_embeddings_2d, columns=[\"tsne_1\", \"tsne_2\"]\n",
    ")\n",
    "code_embeddings_2d[\"code\"] = code_embeddings.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_events = [(i, e[1]) for i, pt in enumerate(train_pos) for e in pt.events]\n",
    "neg_events = [(i, e[1]) for i, pt in enumerate(train_neg) for e in pt.events]\n",
    "\n",
    "pos_events = pd.DataFrame(pos_events, columns=[\"patient\", \"code\"])\n",
    "neg_events = pd.DataFrame(neg_events, columns=[\"patient\", \"code\"])\n",
    "\n",
    "pos_freqs = pos_events.groupby(\"code\")[\"patient\"].nunique().to_frame(name=\"pos_count\")\n",
    "pos_freqs[\"pos_freq\"] = pos_freqs[\"pos_count\"] / pos_events[\"patient\"].nunique()\n",
    "\n",
    "neg_freqs = neg_events.groupby(\"code\")[\"patient\"].nunique().to_frame(name=\"neg_count\")\n",
    "neg_freqs[\"neg_freq\"] = neg_freqs[\"neg_count\"] / neg_events[\"patient\"].nunique()\n",
    "\n",
    "code_embeddings_2d = code_embeddings_2d.merge(\n",
    "    pos_freqs, left_on=\"code\", right_index=True, how=\"left\"\n",
    ")\n",
    "code_embeddings_2d = code_embeddings_2d.merge(\n",
    "    neg_freqs, left_on=\"code\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "code_embeddings_2d[\"rel_freq\"] = (\n",
    "    code_embeddings_2d[\"pos_freq\"] / code_embeddings_2d[\"neg_freq\"]\n",
    ")\n",
    "code_embeddings_2d[\"log_rel_freq\"] = np.log2(code_embeddings_2d[\"rel_freq\"])\n",
    "\n",
    "code_embeddings_2d[\"pos_count\"] = code_embeddings_2d[\"pos_count\"].fillna(0)\n",
    "code_embeddings_2d[\"neg_count\"] = code_embeddings_2d[\"neg_count\"].fillna(0)\n",
    "\n",
    "code_embeddings_2d[\"total_count\"] = code_embeddings_2d[\"pos_count\"] + code_embeddings_2d[\"neg_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=42, n_init=\"auto\")\n",
    "clusters = kmeans.fit_predict(code_embeddings)\n",
    "code_embeddings_2d[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_info_path = \"../../../../../ambit/ambit-csd-analysis/data/ref/diagnosis_codes.csv\"\n",
    "code_info = load_diagnosis_code_info(code_info_path)\n",
    "\n",
    "code_to_description = dict(zip(code_info[\"CODE\"], code_info[\"DESCRIPTION\"]))\n",
    "code_embeddings_2d[\"pheno\"] = code_embeddings_2d[\"code\"].map(code_to_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../../data/temp/code_embeddings.json\"\n",
    "\n",
    "sorted_idx = (\n",
    "    code_embeddings_2d[\"log_rel_freq\"].abs().sort_values(na_position=\"first\").index\n",
    ")\n",
    "\n",
    "(\n",
    "    code_embeddings_2d.loc[sorted_idx]\n",
    "    .reset_index(drop=True)\n",
    "    .to_json(url, orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_max = np.ceil(code_embeddings_2d[\"log_rel_freq\"].abs().max())\n",
    "z_min = -z_max\n",
    "\n",
    "alt.Chart(url).transform_filter(alt.datum.total_count >= 30).mark_circle().encode(\n",
    "    alt.X(\"tsne_1:Q\").axis(None).title(None),\n",
    "    alt.Y(\"tsne_2:Q\").axis(None).title(None),\n",
    "    alt.Color(\"log_rel_freq:Q\").scale(scheme=\"redblue\", domain=(z_min, 0, z_max)),\n",
    "    alt.Size(\"log_rel_freq:Q\")\n",
    "    .scale(range=(200, 50, 200), domain=(z_min, 0, z_max))\n",
    "    .legend(None),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"code:N\", title=\"ICD10 Code\"),\n",
    "        alt.Tooltip(\"pheno:N\", title=\"ICD10 Description\"),\n",
    "        alt.Tooltip(\"log_rel_freq:Q\", format=\".2f\", title=\"Log2 Relative Frequency\"),\n",
    "    ],\n",
    ").properties(width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Embeddings\n",
    "\n",
    "Trajectory embeddings correspond to patient-level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to get inputs in the model\n",
    "# seq = batch_gen.flow(test_pos[:2], test_neg[:2], shuffle=False)\n",
    "# model(seq[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_input = model.encoder.input\n",
    "emb_output = [model.layers[2].layers[-2].output, model.encoder.output]\n",
    "\n",
    "emb_model = keras.Model(inputs=emb_input, outputs=emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patient(\n",
    "    model: keras.Model,\n",
    "    patient: Patient,\n",
    "    max_codes: int,\n",
    "    tokenizer: layers.StringLookup,\n",
    "    max_trajectories: int | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate predictions for all possible trajectories of a patient.\"\"\"\n",
    "    trajectories = patient.get_trajectories()\n",
    "\n",
    "    if max_trajectories is not None and len(trajectories) > max_trajectories:\n",
    "        trajectories = random.sample(trajectories, max_trajectories)\n",
    "\n",
    "    x, (y_true, _) = encode_trajectories(trajectories, max_codes, tokenizer)\n",
    "\n",
    "    y_pred_emb, y_pred = model(x, training=False)\n",
    "\n",
    "    y_pred_emb = pd.DataFrame(y_pred_emb)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "    y_pred_emb.columns = [f\"y_emb_{i}\" for i in range(y_pred_emb.shape[1])]\n",
    "    y_pred.columns = [f\"y_pred_{i}\" for i in range(y_pred.shape[1])]\n",
    "\n",
    "    y_true = pd.DataFrame(y_true)\n",
    "    y_true.columns = [f\"y_true_{i}\" for i in range(y_true.shape[1])]\n",
    "\n",
    "    y_info = pd.DataFrame(\n",
    "        {\n",
    "            \"patient_id\": patient.id,\n",
    "            \"diagnosis_age\": (patient.outcome_date - patient.dob).days / 365,\n",
    "            \"trajectory_age\": x[1][:, -1] / 365,\n",
    "            \"trajectory_len\": (x[1][:, -1] - x[1][:, 0]) / 365\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pd.concat([y_info, y_true, y_pred, y_pred_emb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results = []\n",
    "for pos_pt in tqdm(test_pos):\n",
    "    pos_results.append(\n",
    "        predict_patient(\n",
    "            emb_model,\n",
    "            pos_pt,\n",
    "            cfg.model.max_sequence_length,\n",
    "            model.tokenizer,\n",
    "            max_trajectories=5,\n",
    "        )\n",
    "    )\n",
    "pos_results = pd.concat(pos_results)\n",
    "\n",
    "pos_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_results = []\n",
    "for neg_pt in tqdm(test_neg):\n",
    "    neg_results.append(\n",
    "        predict_patient(\n",
    "            emb_model,\n",
    "            neg_pt,\n",
    "            cfg.model.max_sequence_length,\n",
    "            model.tokenizer,\n",
    "            max_trajectories=5,\n",
    "        )\n",
    "    )\n",
    "neg_results = pd.concat(neg_results)\n",
    "\n",
    "neg_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([pos_results, neg_results])\n",
    "\n",
    "embeddings = results.filter(like=\"y_emb\")\n",
    "embeddings_2d = TSNE(n_components=2, random_state=42).fit_transform(embeddings)\n",
    "embeddings_2d = pd.DataFrame(embeddings_2d, columns=[\"tsne_1\", \"tsne_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = [\"patient_id\", \"diagnosis_age\", \"trajectory_age\", \"trajectory_len\"]\n",
    "results_info = results[info_cols].reset_index(drop=True)\n",
    "results_y_true = results.filter(like=\"y_true\").reset_index(drop=True)\n",
    "results_y_pred = results.filter(like=\"y_pred\").reset_index(drop=True)\n",
    "\n",
    "embeddings_2d = pd.concat(\n",
    "    [results_info, results_y_true, results_y_pred, embeddings_2d], axis=1\n",
    ")\n",
    "\n",
    "embeddings_2d = embeddings_2d.sort_values([\"y_true_4\", \"patient_id\"])\n",
    "embeddings_2d[\"age_bin\"] = np.floor(embeddings_2d[\"trajectory_age\"])\n",
    "\n",
    "embeddings_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../../data/temp/patient_embeddings.json\"\n",
    "embeddings_2d.to_json(url, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart colored by observed label at 60 months\n",
    "TOOLTIP = [\n",
    "    alt.Tooltip(\"patient_id:N\").title(\"Patient ID\"),\n",
    "    alt.Tooltip(\"diagnosis_age:Q\", format=\".2f\").title(\"Diagnosis Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_age:Q\", format=\".2f\").title(\"Trajectory Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_len:Q\", format=\".2f\").title(\"Trajectory Length (yrs)\"),\n",
    "    alt.Tooltip(\"y_pred_4:Q\", format=\".2f\").title(\"Predicted Risk (60 mo.)\"),\n",
    "]\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(url)\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        alt.X(\"tsne_1:Q\").axis(None).title(None),\n",
    "        alt.Y(\"tsne_2:Q\").axis(None).title(None),\n",
    "        alt.Color(\"y_true_4:N\")\n",
    "        .scale(domain=(1, 0), range=(\"#4C78A8\", \"lightgray\"))\n",
    "        .title(\"Observed Diagnosis (60 mo.)\"),\n",
    "        tooltip=TOOLTIP,\n",
    "    )\n",
    "    .properties(width=800, height=500)\n",
    ")\n",
    "\n",
    "chart.configure_view(strokeOpacity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted risk at 60 months\n",
    "TOOLTIP = [\n",
    "    alt.Tooltip(\"patient_id:N\").title(\"Patient ID\"),\n",
    "    alt.Tooltip(\"diagnosis_age:Q\", format=\".2f\").title(\"Diagnosis Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_age:Q\", format=\".2f\").title(\"Trajectory Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_len:Q\", format=\".2f\").title(\"Trajectory Length (yrs)\"),\n",
    "    alt.Tooltip(\"y_pred_4:Q\", format=\".2f\").title(\"Predicted Risk (60 mo.)\"),\n",
    "]\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(url)\n",
    "    .mark_circle()\n",
    "    .encode(\n",
    "        alt.X(\"tsne_1:Q\").axis(None).title(None),\n",
    "        alt.Y(\"tsne_2:Q\").axis(None).title(None),\n",
    "        alt.Color(\"y_pred_4:Q\")\n",
    "        .scale(scheme=\"redblue\", reverse=True, domainMid=0)\n",
    "        .title(\"Predicted Risk (60 mo.)\"),\n",
    "        tooltip=TOOLTIP,\n",
    "    )\n",
    "    .properties(width=800, height=500)\n",
    ")\n",
    "\n",
    "chart.configure_view(strokeOpacity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart colored by the patient's age at the last claim in the trajectory\n",
    "TOOLTIP = [\n",
    "    alt.Tooltip(\"patient_id:N\").title(\"Patient ID\"),\n",
    "    alt.Tooltip(\"diagnosis_age:Q\", format=\".2f\").title(\"Diagnosis Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_age:Q\", format=\".2f\").title(\"Trajectory Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_len:Q\", format=\".2f\").title(\"Trajectory Length (yrs)\"),\n",
    "    alt.Tooltip(\"y_pred_4:Q\", format=\".2f\").title(\"Predicted Risk (60 mo.)\"),\n",
    "]\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(url)\n",
    "    .mark_circle(opacity=0.5)\n",
    "    .encode(\n",
    "        alt.X(\"tsne_1:Q\").axis(None).title(None),\n",
    "        alt.Y(\"tsne_2:Q\").axis(None).title(None),\n",
    "        alt.Color(\"trajectory_len:Q\").title(\"Trajectory Length (yrs)\"),\n",
    "        tooltip=TOOLTIP,\n",
    "    )\n",
    "    .properties(width=800, height=500)\n",
    ")\n",
    "\n",
    "chart.configure_view(strokeOpacity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart colored by the patient's age at the last claim in the trajectory\n",
    "TOOLTIP = [\n",
    "    alt.Tooltip(\"patient_id:N\").title(\"Patient ID\"),\n",
    "    alt.Tooltip(\"diagnosis_age:Q\", format=\".2f\").title(\"Diagnosis Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_age:Q\", format=\".2f\").title(\"Trajectory Age (yrs)\"),\n",
    "    alt.Tooltip(\"trajectory_len:Q\", format=\".2f\").title(\"Trajectory Length (yrs)\"),\n",
    "    alt.Tooltip(\"y_pred_4:Q\", format=\".2f\").title(\"Predicted Risk (60 mo.)\"),\n",
    "]\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(url)\n",
    "    .mark_circle(opacity=0.5)\n",
    "    .encode(\n",
    "        alt.X(\"tsne_1:Q\").axis(None).title(None),\n",
    "        alt.Y(\"tsne_2:Q\").axis(None).title(None),\n",
    "        alt.Color(\"trajectory_age:Q\").title(\"Trajectory Age (yrs)\"),\n",
    "        tooltip=TOOLTIP,\n",
    "    )\n",
    "    .properties(width=800, height=500)\n",
    ")\n",
    "\n",
    "chart.configure_view(strokeOpacity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance By Patient Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"trajectory_age_bin\"] = np.floor(results[\"trajectory_age\"]).astype(int)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_binned_endpoint_metrics = []\n",
    "for age_bin, group in results.groupby(\"trajectory_age_bin\"):\n",
    "    endpoint_metrics = {}\n",
    "    for ep_idx in range(5):\n",
    "        ep_name = cfg.data.month_endpoints[ep_idx]\n",
    "        y_true_ep = group[f\"y_true_{ep_idx}\"]\n",
    "        y_pred_ep = group[f\"y_pred_{ep_idx}\"]\n",
    "        if y_true_ep.nunique() < 2:\n",
    "            continue\n",
    "        endpoint_metrics[ep_name] = compute_endpoint_metrics(y_true_ep, y_pred_ep)\n",
    "    endpoint_metrics = pd.DataFrame.from_dict(endpoint_metrics, orient=\"index\")\n",
    "    endpoint_metrics[\"age_bin\"] = age_bin\n",
    "    age_binned_endpoint_metrics.append(endpoint_metrics)\n",
    "\n",
    "age_binned_endpoint_metrics = (\n",
    "    pd.concat(age_binned_endpoint_metrics).rename_axis(index=\"endpoint\").reset_index()\n",
    ")\n",
    "age_binned_endpoint_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bin_counts = (\n",
    "    results[\"trajectory_age_bin\"]\n",
    "    .value_counts()\n",
    "    .to_frame(\"count\")\n",
    "    .rename_axis(index=\"age_bin\")\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "age_binned_counts_chart = (\n",
    "    alt.Chart(age_bin_counts)\n",
    "    .transform_filter(alt.datum.age_bin <= 15)\n",
    "    .mark_bar(color=\"gray\")\n",
    "    .encode(\n",
    "        alt.X(\"age_bin:O\", title=\"Age Bin\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"count:Q\", title=\"Patient Count\").axis(grid=False),\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "age_binned_auprc_chart = (\n",
    "    alt.Chart(age_binned_endpoint_metrics)\n",
    "    .transform_filter(alt.datum.age_bin <= 15)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\"age_bin:O\", title=\"Age Bin\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"auPRC:Q\", title=\"auPRC\").axis(grid=False),\n",
    "        alt.Color(\"endpoint:O\"),\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "age_binned_auroc_chart = (\n",
    "    alt.Chart(age_binned_endpoint_metrics)\n",
    "    .transform_filter(alt.datum.age_bin <= 15)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\"age_bin:O\", title=\"Age Bin\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"auROC:Q\", title=\"auROC\").axis(grid=False),\n",
    "        alt.Color(\"endpoint:O\"),\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "chart = alt.vconcat(age_binned_counts_chart, age_binned_auprc_chart, age_binned_auroc_chart)\n",
    "chart.configure_view(strokeOpacity=0).configure_axis(titlePadding=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is super interesting -> we can clearly see these two modes where we do well\n",
    "#  occuring for very young patients (<2 yo) and for patients age 8-12\n",
    "# NOTE: we also have really good performance for 0-2 yrs old\n",
    "# NOTE: what if patients get put on an ASM by 2 years old? -> maybe that would explain the dropoff as seizures\n",
    "#   are managed better and we see less claims -> if we add in ASM med claims, maybe we will improve perfomrance in this region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance By Trajectory Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"trajectory_len_bin\"] = np.floor(results[\"trajectory_len\"]).astype(int)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen_binned_endpoint_metrics = []\n",
    "for tlen_bin, group in results.groupby(\"trajectory_len_bin\"):\n",
    "    endpoint_metrics = {}\n",
    "    for ep_idx in range(5):\n",
    "        ep_name = cfg.data.month_endpoints[ep_idx]\n",
    "        y_true_ep = group[f\"y_true_{ep_idx}\"]\n",
    "        y_pred_ep = group[f\"y_pred_{ep_idx}\"]\n",
    "        if y_true_ep.nunique() < 2:\n",
    "            continue\n",
    "        endpoint_metrics[ep_name] = compute_endpoint_metrics(y_true_ep, y_pred_ep)\n",
    "    endpoint_metrics = pd.DataFrame.from_dict(endpoint_metrics, orient=\"index\")\n",
    "    endpoint_metrics[\"tlen_bin\"] = tlen_bin\n",
    "    tlen_binned_endpoint_metrics.append(endpoint_metrics)\n",
    "\n",
    "tlen_binned_endpoint_metrics = (\n",
    "    pd.concat(tlen_binned_endpoint_metrics).rename_axis(index=\"endpoint\").reset_index()\n",
    ")\n",
    "tlen_binned_endpoint_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlen_bin_counts = (\n",
    "    results[\"trajectory_len_bin\"]\n",
    "    .value_counts()\n",
    "    .to_frame(\"count\")\n",
    "    .rename_axis(index=\"tlen_bin\")\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "tlen_binned_counts_chart = (\n",
    "    alt.Chart(tlen_bin_counts)\n",
    "    .transform_filter(alt.datum.tlen_bin <= 15)\n",
    "    .mark_bar(color=\"gray\")\n",
    "    .encode(\n",
    "        alt.X(\"tlen_bin:O\", title=\"Trjectory Length (Yrs)\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"count:Q\", title=\"Patient Count\").axis(grid=False),\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "tlen_binned_auprc_chart = (\n",
    "    alt.Chart(tlen_binned_endpoint_metrics)\n",
    "    .transform_filter(alt.datum.tlen_bin <= 15)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\"tlen_bin:O\", title=\"Trjectory Length (Yrs)\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"auPRC:Q\", title=\"auPRC\").axis(grid=False),\n",
    "        alt.Color(\"endpoint:O\"),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(\"tlen_bin:O\", title=\"Trjectory Length (Yrs)\"),\n",
    "            alt.Tooltip(\"auPRC:Q\", title=\"auROC\"),\n",
    "        ],\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "tlen_binned_auroc_chart = (\n",
    "    alt.Chart(tlen_binned_endpoint_metrics)\n",
    "    .transform_filter(alt.datum.tlen_bin <= 15)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        alt.X(\"tlen_bin:O\", title=\"Trjectory Length (Yrs)\").axis(grid=False, labelAngle=0),\n",
    "        alt.Y(\"auROC:Q\", title=\"auROC\").axis(grid=False),\n",
    "        alt.Color(\"endpoint:O\"),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(\"tlen_bin:O\", title=\"Trjectory Length (Yrs)\"),\n",
    "            alt.Tooltip(\"auROC:Q\", title=\"auROC\"),\n",
    "        ],\n",
    "    )\n",
    "    .properties(width=800, height=200)\n",
    ")\n",
    "\n",
    "chart = alt.vconcat(tlen_binned_counts_chart, tlen_binned_auprc_chart, tlen_binned_auroc_chart)\n",
    "chart.configure_view(strokeOpacity=0).configure_axis(titlePadding=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot length distribution of the embeddings\n",
    "\n",
    "# alt.Chart(url).mark_boxplot().encode(\n",
    "#     alt.X(\"y_true_4:O\").axis(labelAngle=0).title(None),\n",
    "#     alt.Y(\"trajectory_len:Q\")\n",
    "#     .axis(offset=5, grid=False, titlePadding=10)\n",
    "#     .title(\"Trajectory Length (yrs)\"),\n",
    "#     alt.Color(\"y_true_4:O\"),\n",
    "#     alt.Column(\"age_bin:O\").spacing(5).title(\"Age Bin (yrs)\"),\n",
    "# ).configure_view(strokeOpacity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = test_pos[0].sample_trajectories(1)[0]\n",
    "\n",
    "code_seq = trajectory.code_seq\n",
    "value_seq = np.random.normal(0, 1, len(code_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_color(\n",
    "    color1: t.Tuple[int], color2: t.Tuple[int], n: float\n",
    ") -> t.Tuple[int]:\n",
    "    \"\"\"Interpolate between two colors.\"\"\"\n",
    "    return tuple(round(color1[i] + (color2[i] - color1[i]) * n) for i in range(3))\n",
    "\n",
    "\n",
    "def create_diverging_color_scheme(\n",
    "    color1: t.Tuple[int], color2: t.Tuple[int], color3: t.Tuple[int]\n",
    ") -> t.List[t.Tuple[int]]:\n",
    "    \"\"\"Create a diverging color scheme.\"\"\"\n",
    "    colors_1 = [interpolate_color(color1, color2, n) for n in np.arange(0, 1, 0.1)]\n",
    "    colors_2 = [interpolate_color(color3, color2, n) for n in np.arange(0, 1, 0.1)]\n",
    "\n",
    "    return colors_1 + [color2] + list(reversed(colors_2))\n",
    "\n",
    "\n",
    "def create_color_scheme(\n",
    "    color1: t.Tuple[int], color2: t.Tuple[int]\n",
    ") -> t.List[t.Tuple[int]]:\n",
    "    \"\"\"Create a color scheme.\"\"\"\n",
    "    return [interpolate_color(color1, color2, n) for n in np.arange(0, 1.1, 0.1)]\n",
    "\n",
    "\n",
    "red_rgb = (229, 87, 86)  # red\n",
    "gray_rgb = (241, 239, 238)  # gray\n",
    "blue_rgb = (76, 120, 168)  # blue\n",
    "purple_rgb = (178, 120, 162)  # purple\n",
    "\n",
    "colors = create_diverging_color_scheme(blue_rgb, gray_rgb, red_rgb)\n",
    "colors = [\"#%02X%02X%02X\" % c for c in colors]\n",
    "\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"{i}\" for i in range(len(colors))]\n",
    "bin_seq = pd.cut(value_seq, bins=len(colors), labels=labels)\n",
    "bin_to_color = dict(zip(labels, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALIENCY_MAP_HTML_TEMPLATE = \"\"\"\n",
    "    <style>\n",
    "        .container {{\n",
    "            display: flex;\n",
    "            flex-wrap: wrap;\n",
    "            font-size: 1em;\n",
    "            margin: 100px;\n",
    "            max-width: 75%;\n",
    "        }}\n",
    "        .code {{\n",
    "            color: black;\n",
    "            border-radius: 2px;\n",
    "            margin: 2px;\n",
    "            padding: 5px;\n",
    "        }}\n",
    "        .tooltip-text {{\n",
    "            background-color: white;\n",
    "            border-radius: 5px;\n",
    "            color: black;\n",
    "            position: absolute;\n",
    "            visibility: hidden;\n",
    "            z-index: 1;\n",
    "            padding-left: 10px;\n",
    "            padding-right: 10px;\n",
    "        }}\n",
    "        .tooltip:hover .tooltip-text {{\n",
    "            visibility: visible;\n",
    "        }}\n",
    "    </style>\n",
    "    <div class='container'>\n",
    "        {0}\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SALIENCY_MAP_DIV_HTML_TEMPLATE = \"\"\"\n",
    "    <div class='code tooltip' style='background-color:{0}'>\n",
    "        {1}\n",
    "        <div class='tooltip-text'>\n",
    "            <p style='font-size:0.9em'>Code: {2}</p>\n",
    "            <p style='font-size:0.9em'>Age: {3}</p>\n",
    "            <p style='font-size:0.9em'>Decription: {4}</p>\n",
    "            <p style='font-size:0.9em'>Integrated Gradients: {5:.2f}</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SaliencyMapPlotter:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        codes: t.Iterable[str],\n",
    "        ages: t.Iterable[float],\n",
    "        values: t.List[float],\n",
    "        colors: t.List[t.Tuple[int]],\n",
    "    ) -> None:\n",
    "        self.codes = codes\n",
    "        self.ages = ages\n",
    "        self.values = values\n",
    "        self._colors = colors\n",
    "        self._init_color_scheme(colors)\n",
    "        self._init_bins()\n",
    "\n",
    "    def _init_bins(self) -> None:\n",
    "        \"\"\"\"\"\"\n",
    "        labels = [f\"{i}\" for i in range(len(self._scheme))]\n",
    "        self.bins = pd.cut(self.values, bins=len(self._scheme), labels=labels)\n",
    "        self.bin_to_color = dict(zip(labels, self._scheme))\n",
    "\n",
    "    def _init_color_scheme(self, colors: t.List[t.Tuple[int]]) -> t.List[str]:\n",
    "        \"\"\"\"\"\"\n",
    "        if len(colors) == 3:\n",
    "            scheme = create_diverging_color_scheme(*colors)\n",
    "        elif len(colors) == 2:\n",
    "            scheme = create_color_scheme(*colors)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid no of colors.\")\n",
    "\n",
    "        self._scheme = [\"#%02X%02X%02X\" % c for c in scheme]\n",
    "\n",
    "    def plot(self) -> HTML:\n",
    "        \"\"\"\"\"\"\n",
    "        inner = \"\"\n",
    "        for c, a, v, b in zip(self.codes, self.ages, self.values, self.bins):\n",
    "            inner += SALIENCY_MAP_DIV_HTML_TEMPLATE.format(\n",
    "                self.bin_to_color[b], c, c, a, code_to_description.get(c, \"N/A\"), v\n",
    "            )\n",
    "        return HTML(SALIENCY_MAP_HTML_TEMPLATE.format(inner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_sequence(baseline, sequence, alphas):\n",
    "    \"\"\"Generate interpolated sequence embeddings.\"\"\"\n",
    "    input_x = sequence\n",
    "    baseline_x = baseline\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis]\n",
    "\n",
    "    delta = input_x - baseline_x\n",
    "    return baseline_x + alphas_x * delta\n",
    "\n",
    "\n",
    "def compute_gradients(model: keras.Model, sequences, target_class_idx: int = -1):\n",
    "    \"\"\"\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(sequences)\n",
    "        logits = model(sequences)\n",
    "        # probs = ops.sigmoid(logits)[:, target_class_idx]\n",
    "        probs = logits[:, target_class_idx]\n",
    "\n",
    "    return tape.gradient(probs, sequences)\n",
    "\n",
    "\n",
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "def integrated_gradients(\n",
    "    model: keras.Model,\n",
    "    sequence,\n",
    "    mask,\n",
    "    target_class_idx: int = -1,\n",
    "    baseline: np.ndarray | None = None,\n",
    "    n_steps: int = 50,\n",
    "):\n",
    "    \"\"\"\"\"\"\n",
    "    if baseline is None:\n",
    "        baseline = tf.zeros_like(sequence)\n",
    "\n",
    "    alphas = tf.linspace(0.0, 1.0, n_steps + 1)\n",
    "\n",
    "    interpolated_sequences = interpolate_sequence(baseline, sequence, alphas)\n",
    "\n",
    "    path_gradients = compute_gradients(\n",
    "        model, sequences=interpolated_sequences, target_class_idx=target_class_idx\n",
    "    )\n",
    "\n",
    "    avg_gradients = integral_approximation(path_gradients)\n",
    "    avg_gradients *= ops.expand_dims(mask, axis=1)\n",
    "\n",
    "    integrated_gradients = (sequence - baseline) * avg_gradients\n",
    "\n",
    "    return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: account for padding in gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_lookup = layers.StringLookup(\n",
    "    mask_token=\"\", invert=True, vocabulary=model.tokenizer.get_vocabulary()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ((255, 255, 255), purple_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "alphas = tf.linspace(start=0.0, stop=1.0, num=n_steps + 1)\n",
    "\n",
    "patient: Patient = train_pos[3]\n",
    "\n",
    "valid_trajectories = patient.get_trajectories()\n",
    "\n",
    "x, y = encode_trajectories(\n",
    "    [valid_trajectories[0]], cfg.model.max_sequence_length, model.tokenizer\n",
    ")\n",
    "\n",
    "embedding_layer = model.encoder.layers[2]\n",
    "ig_model = keras.models.Sequential(model.encoder.layers[3:])\n",
    "\n",
    "x_embedding = embedding_layer(x)[0].numpy()\n",
    "x_mask = tf.cast(x[0][0] != 0, dtype=tf.float32)\n",
    "\n",
    "attributions = integrated_gradients(ig_model, x_embedding, x_mask)\n",
    "\n",
    "# sum attributions over the embedding dimension\n",
    "attributions = tf.reduce_sum(attributions, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add saving of StringLookup and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process attributions for visualization\n",
    "\n",
    "# positive polarity\n",
    "attributions = np.clip(attributions, 0, 1)\n",
    "\n",
    "# get thresholded attributions\n",
    "clip_above_percentile = 99.9\n",
    "clip_below_percentile = 10.0\n",
    "lower_end = 0.2\n",
    "\n",
    "flatten_attr = attributions.flatten()\n",
    "\n",
    "total = np.sum(flatten_attr)\n",
    "\n",
    "sorted_attributions = np.sort(np.abs(flatten_attr))[::-1]\n",
    "cum_sum = 100.0 * np.cumsum(sorted_attributions) / total\n",
    "\n",
    "indices_to_consider = np.where(cum_sum >= 100 - clip_above_percentile)[0][0]\n",
    "m = sorted_attributions[indices_to_consider]\n",
    "\n",
    "indices_to_consider = np.where(cum_sum >= 100 - clip_below_percentile)[0][0]\n",
    "e = sorted_attributions[indices_to_consider]\n",
    "\n",
    "transformed_attributions = (1 - lower_end) * (np.abs(attributions) - e) / (\n",
    "    m - e\n",
    ") + lower_end\n",
    "\n",
    "transformed_attributions *= np.sign(attributions)\n",
    "transformed_attributions *= transformed_attributions >= lower_end\n",
    "transformed_attributions = np.clip(transformed_attributions, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(\n",
    "    {\"code\": reverse_lookup(x[0][0]), \"age\": x[1][0], \"ig\": transformed_attributions}\n",
    ")\n",
    "result[\"code\"] = result[\"code\"].str.decode(\"utf-8\")\n",
    "result[\"code\"] = result[\"code\"].map(lambda x: \"[PAD]\" if x == \"\" else x)\n",
    "\n",
    "# filter padding tokens\n",
    "result = result[result[\"code\"] != \"[PAD]\"]\n",
    "result[\"age\"] = (result[\"age\"] / 365).round(2)\n",
    "result[\"idx\"] = range(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = alt.Chart(result).encode(alt.X(\"idx:N\").axis().sort(list(result[\"idx\"])))\n",
    "base.mark_circle().encode(alt.Y(\"ig:Q\").axis(grid=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = SaliencyMapPlotter(\n",
    "    list(result[\"code\"]), list((result[\"age\"] / 365).round(2)), list(result[\"ig\"]), colors=colors\n",
    ")\n",
    "plotter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: what if I display the trajectory along a vertical axis - each row is a code, age, desc, and IG value\n",
    "# NOTE: alternatively, I can display it as a lolipop plot showing the IG values for each code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate a \"most recent\" generatator that only gabs the most recent trajectory from the valid trajectories\n",
    "\n",
    "batch_gen = RiskNetBatchGenerator(\n",
    "    batch_size=256,\n",
    "    tokenizer=model.tokenizer,\n",
    "    max_codes=cfg.model.max_sequence_length,\n",
    "    n_trajectories=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: what if I boostrap it with half of each number of patients?\n",
    "\n",
    "frac = 1.0\n",
    "n_pos = int(121 * frac)\n",
    "n_neg = int(9597 * frac)\n",
    "n_bootstrap_iters = 100\n",
    "\n",
    "bootstrap_scores = []\n",
    "for i in trange(n_bootstrap_iters):\n",
    "    batch_pos = PatientCollection(*np.random.choice(test_pos, n_pos, replace=True))\n",
    "    batch_neg = PatientCollection(*np.random.choice(test_neg, n_neg, replace=True))\n",
    "\n",
    "    eval_scores = get_eval_scores(\n",
    "        model,\n",
    "        batch_gen.flow(batch_pos, batch_neg, shuffle=False),\n",
    "        class_labels=cfg.data.month_endpoints,\n",
    "    )\n",
    "\n",
    "    endpoint_scores = (\n",
    "        pd.DataFrame.from_dict(eval_scores[\"endpoint_metrics\"], orient=\"index\")\n",
    "        .assign(iter=i)\n",
    "        .rename_axis(\"endpoint\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    bootstrap_scores.append(endpoint_scores)\n",
    "\n",
    "bootstrap_scores = pd.concat(bootstrap_scores)\n",
    "bootstrap_scores.groupby(\"endpoint\").agg(\"mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udn-modeling-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
